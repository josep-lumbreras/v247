---
title: Linear bandits with polylogarithmic minimax regret
section: Original Papers
abstract: " We study a noise model for linear stochastic bandits for which the subgaussian
  noise parameter vanishes linearly as we select actions on the unit sphere closer
  and closer to the unknown vector.  We introduce an algorithm for this problem that
  exhibits a minimax regret scaling as $\\log^3(T)$ in the time horizon $T$, in stark
  contrast the square root scaling of this regret for typical bandit algorithms. Our
  strategy, based on weighted least-squares estimation, achieves the eigenvalue relation
  \ $\\lambda_{\\min} ( V_t ) = \\Omega (\\sqrt{\\lambda_{\\max}(V_t ) })$ for the
  design matrix $V_t$ at each time step $t$ through geometrical arguments that are
  independent of the noise model and might be of independent interest. This allows
  us to tightly control the expected regret in each time step to be of the order $O(\\frac1{t})$,
  leading to the logarithmic scaling of the cumulative regret."
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lumbreras24a
month: 0
tex_title: Linear bandits with polylogarithmic minimax regret
firstpage: 3644
lastpage: 3682
page: 3644-3682
order: 3644
cycles: false
bibtex_author: Lumbreras, Josep and Tomamichel, Marco
author:
- given: Josep
  family: Lumbreras
- given: Marco
  family: Tomamichel
date: 2024-06-30
address:
container-title: Proceedings of Thirty Seventh Conference on Learning Theory
volume: '247'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 6
  - 30
pdf: https://proceedings.mlr.press/v247/lumbreras24a/lumbreras24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
